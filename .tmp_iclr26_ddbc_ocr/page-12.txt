Under review as a conference paper at ICLR 2026

Bowen Zheng, Yupeng Hou, Hongyu Lu, Yu Chen, Wayne Xin Zhao, Ming Chen, and Ji-Rong Wen.
Adapting large language models by integrating collaborative semantics for recommendation. In
ICDE, pp. 1435-1448. IEEE, 2024.

A THE USE OF LARGE LANGUAGE MODELS

We used large language models (e.g., ChatGPT 5, Claude) as an assistive tool for writing polish
(grammar, phrasing, and LaTeX formatting), troubleshooting LaTeX errors, and scaffolding non-
critical scripts (plotting and small utilities). LLMs did not contribute novel scientific ideas, data
collection, or result selection, and any code snippets suggested by an LLM were reviewed, rewritten
where necessary, and validated by the authors. All technical claims, mathematical formulations,
and empirical results are the authors’ responsibility. LLMs are not listed as authors and have no
authorship rights.

B IMPLEMENTATION DETAILS

Dataset statistics. The statistics for the datasets used in our experiments are summarized in Table
(| All Spotify series dataset share a large item catalog size (N) of 254,155, with a massive candidate
space. Density Spotify,,39 > Spotify,_¢9 > Spotify, 99. Conversely, the POG;,—, dataset features
a substantially smaller item catalog size (N) of 31,217 and contains a more consistent number of
bundles across the splits (e.g, Mirain = 29,704). This variation in item catalog size and bundle
count allows for a comprehensive evaluation of our method’s scalability and performance under
different data density conditions.

Data augmentation. To improve the model’s robustness and prevent the bundle overfit to the default
sequential item order of the bundle, we employ a data augmentation strategy based on item swap-
ping. Specifically, for each original item sequence, we performed a series of adjacent item swaps
on a copy of the sequence. For the POG dense dataset, we set swap ratio 0.8, and for the Spotify
datasets, we used swap ratio 0.4. Subsequently, we randomly sampled a fixed-length subsequence
(sequence length) from the perturbed sequence, creating a new augmented training instance. This
data augmentation is an enhancement to the diffusion model, fulfilling the non-sequential modeling
objective while countering the potential issue of overfitting to the certain given sequential order in
the bundle.

Over-retrieval. To standardize the evaluation of generative models which can produce multiple
possible outputs, we employ an Over-Retrieval Strategy. This strategy aggregates the results from
multiple generation attempts, effectively forming the union By used in the retrieval-based metrics.
For generative sampling models, we evaluate performance under a varying number of attempts b €
{1,5, 10, 20, 50} (denoted as Multiple Sampling, MS). For auto-regressive baselines that use beam
search, we report the results using beam width b € {1,3,5, 10, 20, 50}, mapping the beam width to
the number of attempts (X = b) for a fair comparison of computational cost.

Table 6: Dataset statistics. N is the catalog size (total number of items in the dataset); Mtrainwattest
are the number of bundles in train/val/test sets.

Dataset N Mrain Mya Mest

Spotify, 49 254,155 321,929 1,374 2,744
Spotify,—gq 254,155 253,358 798 1,582
Spotify, oq 254,155 188,618 463 969
POGk=4 31,217 29,704 1,303 2,521

Input tokenization for bundles (details). Given b = {i1,...,%j5)} with item codes z(i;) =

(2j,15+++5%),L)s the serialized sequence is

x = (<bos>, <boi>, 21,1,---; 21,2, <bOi>, 221,--., 22,1, -++, <DOA>, Zpj1,---52|o],b, <e0S8>).
(10)

Its length is U = 2 + |b|(Z+1). Define the index map for item j and level ¢:
u(j,0) = 1+ (j-1)(£+1) +1, u(j,@) = u(j,0) +4, @e {1,...,L}. (nD)

13
